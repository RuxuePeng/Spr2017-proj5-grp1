Test.y<-test_data_festures[,c(ncol(test_data_festures)-1)]
Train.x<- data.matrix(Train.x,rownames.force = NA)
Train.D <- xgb.DMatrix(data=Train.x,label=Train.y,missing = NaN)
Test.x<- data.matrix(Test.x,rownames.force = NA)
Test.D <- xgb.DMatrix(data=Test.x,label=Test.y,missing = NaN)
depth.choice<- c(5,6,7,8)
eta.choice<- seq(0.1,0.5,0.1)
error<-matrix(NA,nrow = length(eta.choice),ncol = length(depth.choice))
iteration<-matrix(NA,nrow = length(eta.choice),ncol = length(depth.choice))
train.sd<-matrix(NA,nrow = length(eta.choice),ncol = length(depth.choice))
test.sd<-matrix(NA,nrow = length(eta.choice),ncol = length(depth.choice))
for (i in 1:length(depth.choice)) {
for (j in 1:length(eta.choice) ) {
parameters <- list ( objective = "binary:logistic",
#booser = "gbtree",
eta = eta.choice[j],
max_depth = depth.choice[i],
subsample = 0.5,
gamma = 0)
crossvalid <- xgb.cv( params = parameters,
data = Train.D,
nrounds = 100,
verbose = 1,
maximize = FALSE,
nfold = 5,
early_stopping_rounds = 8,
print_every_n = 1)
iteration[j,i]<-crossvalid$best_iteration
error[j,i]<-as.numeric(crossvalid$evaluation_log[crossvalid$best_iteration,4])
}
}
best.index<-which(error == min(error), arr.ind = TRUE)
best.index<-which(error == min(error), arr.ind = TRUE)
depth.choose<-depth.choice[best.index[1,2]]
era.choose<-eta.choice[best.index[1,1]]
iteration.choose<-iteration[best.index[1,1],best.index[1,2]]
parameters <- list ( objective = "binary:logistic",
#booser = "gbtree",
eta = era.choose,
max_depth = depth.choose,
subsample = 0.5,
gamma = 0)
fit_xgboost<-xgb.train( params              = parameters,
data                = Train.D,
nrounds             = 100,
verbose             = 1,
maximize            = FALSE)
prediction <- predict (fit_xgboost,Test.x)
prediction<-as.numeric(prediction > 0.5)
mean(prediction!=Test.y)
prediction2 <- predict (fit_xgboost,Train.x)
prediction2<-as.numeric(prediction2 > 0.5)
mean(prediction2!=Train.y)
for (i in 1:length(depth.choice)) {
for (j in 1:length(eta.choice) ) {
parameters <- list ( objective = "binary:logistic",
#booser = "gbtree",
eta = eta.choice[j],
max_depth = depth.choice[i],
subsample = 0.5,
gamma = 0)
crossvalid <- xgb.cv( params = parameters,
data = Train.D,
nrounds = 100,
verbose = F,
maximize = FALSE,
nfold = 5,
early_stopping_rounds = 8,
print_every_n = 1)
iteration[j,i]<-crossvalid$best_iteration
error[j,i]<-as.numeric(crossvalid$evaluation_log[crossvalid$best_iteration,4])
}
}
best.index<-which(error == min(error), arr.ind = TRUE)
depth.choose<-depth.choice[best.index[1,2]]
era.choose<-eta.choice[best.index[1,1]]
iteration.choose<-iteration[best.index[1,1],best.index[1,2]]
parameters <- list ( objective = "binary:logistic",
#booser = "gbtree",
eta = era.choose,
max_depth = depth.choose,
subsample = 0.5,
gamma = 0)
fit_xgboost<-xgb.train( params              = parameters,
data                = Train.D,
nrounds             = 100,
verbose             = 1,
maximize            = FALSE)
prediction <- predict (fit_xgboost,Test.x)
prediction<-as.numeric(prediction > 0.5)
mean(prediction!=Test.y)
prediction2 <- predict (fit_xgboost,Train.x)
prediction2<-as.numeric(prediction2 > 0.5)
mean(prediction2!=Train.y)
#### Load trainging and testing data:
#### Source function:
source("../lib/function.R")
#### Specify Path:
train.path="../data/PerGame_2015/"
test.path="../data/PerGame_playoff_2016/"
tra=list.files(path = train.path, pattern = "*.csv")
tes=list.files(path = test.path, pattern = "*.csv")
tra1<-substr(tra, start=1, stop=nchar(tra)-9)
tes1<-substr(tes, start=1, stop=nchar(tes)-9)
train_data<-as.list(1:length(tra))
test_data<-as.list(1:length(tes))
names(train_data)<-tra
names(test_data)<-tes
## Read as list:
for (i in tra){
train_data[[i]]<-read.csv(paste(train.path,i,sep = ""),header = T,as.is=T)
}
# for (i in tes){
#  test_data[[i]]<-read.csv(paste(test.path,i,sep = ""),header = T,as.is=T)
#}
## Data Cleaning
train_data<-lapply(train_data,clean_data)
## get historical performace
## Get the time-weighted averge performance
wt<-0.9^seq(82, 1, by = -1)
wt<-wt/sum(wt)
Ave_performace<-lapply(train_data,get_average,weight=wt)
Ave_performace<-Reduce(rbind,Ave_performace)
d<-ncol(Ave_performace)
rownames(Ave_performace)<-tes1
tes1
test_data<-read.csv("../data/Test.csv")
test_data_festures<-test_data
n_test<-nrow(test_data)
d_test<-ncol(test_data)
View(test_data)
i<-1
names(test_data)
teamA<-test_data$TeamA[i]
opp<-test_data$Opp[i]
tes1
ind1<-which(tes1==teamA)
ind2<-which(tes1==opp)
test_data_features
dim(test_data_features)
test_data_features[i,3:34]<-c(Ave_performace[ind1,],Ave_performace[ind2,])
ind1
ind2
teamA
opp
(Ave_performace[ind1,]+as.numeric(test_data[i,3:18]))/2
Ave_performance
Ave_performace
Ave_perf
#### Load trainging and testing data:
#### Source function:
source("../lib/function.R")
#### Specify Path:
train.path="../data/PerGame_2015/"
test.path="../data/PerGame_playoff_2016/"
tra=list.files(path = train.path, pattern = "*.csv")
tes=list.files(path = test.path, pattern = "*.csv")
tra1<-substr(tra, start=1, stop=nchar(tra)-9)
tes1<-substr(tes, start=1, stop=nchar(tes)-9)
train_data<-as.list(1:length(tra))
test_data<-as.list(1:length(tes))
names(train_data)<-tra
names(test_data)<-tes
## Read as list:
for (i in tra){
train_data[[i]]<-read.csv(paste(train.path,i,sep = ""),header = T,as.is=T)
}
# for (i in tes){
#  test_data[[i]]<-read.csv(paste(test.path,i,sep = ""),header = T,as.is=T)
#}
## Data Cleaning
train_data<-lapply(train_data,clean_data)
## get historical perf
## Get the time-weighted averge performance
wt<-0.9^seq(82, 1, by = -1)
wt<-wt/sum(wt)
Ave_perf<-lapply(train_data,get_average,weight=wt)
Ave_perf<-Reduce(rbind,Ave_perf)
d<-ncol(Ave_perf)
rownames(Ave_perf)<-tes1
## Obtain the test data:
test_data<-read.csv("../data/Test.csv")
test_data_features<-test_data
n_test<-nrow(test_data)
d_test<-ncol(test_data)
Ave_perf
#### Load trainging and testing data:
#### Source function:
source("../lib/function.R")
#### Specify Path:
train.path="../data/PerGame_2015/"
test.path="../data/PerGame_playoff_2016/"
tra=list.files(path = train.path, pattern = "*.csv")
tes=list.files(path = test.path, pattern = "*.csv")
tra1<-substr(tra, start=1, stop=nchar(tra)-9)
tes1<-substr(tes, start=1, stop=nchar(tes)-9)
train_data<-as.list(1:length(tra))
test_data<-as.list(1:length(tes))
names(train_data)<-tra
names(test_data)<-tes
## Read as list:
for (i in tra){
train_data[[i]]<-read.csv(paste(train.path,i,sep = ""),header = T,as.is=T)
}
# for (i in tes){
#  test_data[[i]]<-read.csv(paste(test.path,i,sep = ""),header = T,as.is=T)
#}
## Data Cleaning
train_data<-lapply(train_data,clean_data)
## get historical perf
## Get the time-weighted averge performance
wt<-0.9^seq(82, 1, by = -1)
wt<-wt/sum(wt)
ave_perf<-lapply(train_data,get_average,weight=wt)
ave_perf<-Reduce(rbind,ave_perf)
d<-ncol(ave_perf)
rownames(ave_perf)<-tes1
## Obtain the test data:
test_data<-read.csv("../data/Test.csv")
test_data_features<-test_data
n_test<-nrow(test_data)
d_test<-ncol(test_data)
rm(list=ls())
#### Load trainging and testing data:
#### Source function:
source("../lib/function.R")
#### Specify Path:
train.path="../data/PerGame_2015/"
test.path="../data/PerGame_playoff_2016/"
tra=list.files(path = train.path, pattern = "*.csv")
tes=list.files(path = test.path, pattern = "*.csv")
tra1<-substr(tra, start=1, stop=nchar(tra)-9)
tes1<-substr(tes, start=1, stop=nchar(tes)-9)
train_data<-as.list(1:length(tra))
test_data<-as.list(1:length(tes))
names(train_data)<-tra
names(test_data)<-tes
## Read as list:
for (i in tra){
train_data[[i]]<-read.csv(paste(train.path,i,sep = ""),header = T,as.is=T)
}
# for (i in tes){
#  test_data[[i]]<-read.csv(paste(test.path,i,sep = ""),header = T,as.is=T)
#}
## Data Cleaning
train_data<-lapply(train_data,clean_data)
## get historical perf
## Get the time-weighted averge performance
wt<-0.9^seq(82, 1, by = -1)
wt<-wt/sum(wt)
ave_perf<-lapply(train_data,get_average,weight=wt)
ave_perf<-Reduce(rbind,ave_perf)
d<-ncol(ave_perf)
rownames(ave_perf)<-tes1
## Obtain the test data:
test_data<-read.csv("../data/Test.csv")
test_data_features<-test_data
n_test<-nrow(test_data)
d_test<-ncol(test_data)
for(i in 1:n_test){
teamA<-test_data$TeamA[i]
opp<-test_data$Opp[i]
ind1<-which(tes1==teamA)
ind2<-which(tes1==opp)
test_data_features[i,3:34]<-c(ave_perf[ind1,],ave_perf[ind2,])
ave_perf[ind1,]<-(ave_perf[ind1,]+as.numeric(test_data[i,3:18]))/2
ave_perf[ind2,]<-(ave_perf[ind2,]+as.numeric(test_data[i,19:34]))/2
}
train_data<-Reduce(rbind,train_data)
test_data_features
dim(test_data_features)
172/16
test_data_features<-test_data_features[,-c(1,2)]
dim(test_data_features)
dim(train_data)
dim(test_data_features)
colnames(train_data)
colnames(test_data)
typeof(train_data)
typeof(test_data_features)
ncol(train_data)-1
Train.x<- data.matrix(train_data[,-(ncol(train_data)-1)])
name(Train.x)
names(Train.x)
names(Train.x)
names(train_data)
Train.x<- data.matrix(train_data[,-y])
Train.x<- data.matrix(train_data[,-"y"])
Train.x<- data.matrix(train_data[,-$y])
train_data[,-"y"]
train_data[,-c("y")]
Train.x<- data.matrix(train_data[,-(ncol(train_data)-1)])
Train.y<-train_data[,(ncol(train_data)-1)]
Train.y
Test.x<-data.matrix(test_data_features[,-c(ncol(test_data_features)-1)])
Test.y<-test_data_features[,c(ncol(test_data_features)-1)]
Train.x<- data.matrix(Train.x,rownames.force = NA)
Train.D <- xgb.DMatrix(data=Train.x,label=Train.y,missing = NaN)
Test.x<- data.matrix(Test.x,rownames.force = NA)
Test.D <- xgb.DMatrix(data=Test.x,label=Test.y,missing = NaN)
depth.choice<- c(5,6,7,8)
eta.choice<- seq(0.1,0.5,0.1)
error<-matrix(NA,nrow = length(eta.choice),ncol = length(depth.choice))
iteration<-matrix(NA,nrow = length(eta.choice),ncol = length(depth.choice))
train.sd<-matrix(NA,nrow = length(eta.choice),ncol = length(depth.choice))
test.sd<-matrix(NA,nrow = length(eta.choice),ncol = length(depth.choice))
for (i in 1:length(depth.choice)) {
for (j in 1:length(eta.choice) ) {
parameters <- list ( objective = "binary:logistic",
#booser = "gbtree",
eta = eta.choice[j],
max_depth = depth.choice[i],
subsample = 0.5,
gamma = 0)
crossvalid <- xgb.cv( params = parameters,
data = Train.D,
nrounds = 100,
verbose = F,
maximize = FALSE,
nfold = 5,
early_stopping_rounds = 8,
print_every_n = 1)
iteration[j,i]<-crossvalid$best_iteration
error[j,i]<-as.numeric(crossvalid$evaluation_log[crossvalid$best_iteration,4])
}
}
best.index<-which(error == min(error), arr.ind = TRUE)
depth.choose<-depth.choice[best.index[1,2]]
era.choose<-eta.choice[best.index[1,1]]
iteration.choose<-iteration[best.index[1,1],best.index[1,2]]
parameters <- list ( objective = "binary:logistic",
#booser = "gbtree",
eta = era.choose,
max_depth = depth.choose,
subsample = 0.5,
gamma = 0)
fit_xgboost<-xgb.train( params              = parameters,
data                = Train.D,
nrounds             = 100,
verbose             = 1,
maximize            = FALSE)
Test.x
prediction <- predict (fit_xgboost,Test.x)
prediction
dim(prediction)
length(prediction)
prediction2 <- predict (fit_xgboost,Train.x)
prediction2<-as.numeric(prediction2 > 0.5)
mean(prediction2!=Train.y)
mean(prediction!=Test.y)
prediction <- predict (fit_xgboost,Test.x)
prediction<-as.numeric(prediction > 0.5)
mean(prediction!=Test.y)
plot(wt)
get_average
matrix(rep(wt,d),nrow = n,byrow = F)
n<-nrow(train_data)
matrix(rep(wt,d),nrow = n,byrow = F)
get_average
dim(weight)
weight<-matrix(rep(wt,d),nrow = n,byrow = F)
dim(weight)
dim(train_data)
n_test
test_data_features$y
prediction <- predict (fit_xgboost,Test.x)
prediction
length(prediction)
prediction<-as.numeric(prediction > 0.5)
length(prediction)
prediction
test_data_features$y
View(Train.x)
rm(list=ls())
#### Load trainging and testing data:
#### Source function:
source("../lib/function.R")
#### Specify Path:
train.path="../data/PerGame_2015/"
test.path="../data/PerGame_playoff_2016/"
tra=list.files(path = train.path, pattern = "*.csv")
tes=list.files(path = test.path, pattern = "*.csv")
tra1<-substr(tra, start=1, stop=nchar(tra)-9)
tes1<-substr(tes, start=1, stop=nchar(tes)-9)
train_data<-as.list(1:length(tra))
test_data<-as.list(1:length(tes))
names(train_data)<-tra
names(test_data)<-tes
## Read as list:
for (i in tra){
train_data[[i]]<-read.csv(paste(train.path,i,sep = ""),header = T,as.is=T)
}
# for (i in tes){
#  test_data[[i]]<-read.csv(paste(test.path,i,sep = ""),header = T,as.is=T)
#}
## Data Cleaning
train_data<-lapply(train_data,clean_data)
View(train_data)
train_data<-Reduce(rbind,train_data)
View(train_data)
#### Load trainging and testing data:
#### Source function:
source("../lib/function.R")
#### Specify Path:
train.path="../data/PerGame_2015/"
test.path="../data/PerGame_playoff_2016/"
tra=list.files(path = train.path, pattern = "*.csv")
tes=list.files(path = test.path, pattern = "*.csv")
tra1<-substr(tra, start=1, stop=nchar(tra)-9)
tes1<-substr(tes, start=1, stop=nchar(tes)-9)
train_data<-as.list(1:length(tra))
test_data<-as.list(1:length(tes))
names(train_data)<-tra
names(test_data)<-tes
## Read as list:
for (i in tra){
train_data[[i]]<-read.csv(paste(train.path,i,sep = ""),header = T,as.is=T)
}
# for (i in tes){
#  test_data[[i]]<-read.csv(paste(test.path,i,sep = ""),header = T,as.is=T)
#}
## Data Cleaning
train_data<-lapply(train_data,clean_data)
View(train_data)
train_data[[1]]
train_data
names(train_data)
i<-1
paste(train.path,i,sep = ""
)
paste(train.path,i,sep = "")
tra
for (i in tra){
train_data[[i]]<-read.csv(paste(train.path,i,sep = ""),header = T,as.is=T)
}
train_data[[1]]
clean_data
train_data<-lapply(train_data,clean_data)
wt<-0.9^seq(82, 1, by = -1)
wt<-wt/sum(wt)
ave_perf<-lapply(train_data,get_average,weight=wt)
matrix(rep(wt,d),nrow = n,byrow = F)
ave_perf<-Reduce(rbind,ave_perf)
d<-ncol(ave_perf)
rownames(ave_perf)<-tes1
test_data<-read.csv("../data/Test.csv")
test_data_features<-test_data
n_test<-nrow(test_data)
d_test<-ncol(test_data)
for(i in 1:n_test){
teamA<-test_data$TeamA[i]
opp<-test_data$Opp[i]
ind1<-which(tes1==teamA)
ind2<-which(tes1==opp)
test_data_features[i,3:34]<-c(ave_perf[ind1,],ave_perf[ind2,])
ave_perf[ind1,]<-(ave_perf[ind1,]+as.numeric(test_data[i,3:18]))/2
ave_perf[ind2,]<-(ave_perf[ind2,]+as.numeric(test_data[i,19:34]))/2
}
train_data<-Reduce(rbind,train_data)
test_data_features<-test_data_features[,-c(1,2)]
library(xgboost)
Train.x<- data.matrix(train_data[,-(ncol(train_data)-1)])
Train.y<-train_data[,(ncol(train_data)-1)]
Test.x<-data.matrix(test_data_features[,-c(ncol(test_data_features)-1)])
Test.y<-test_data_features[,c(ncol(test_data_features)-1)]
Train.x<- data.matrix(Train.x,rownames.force = NA)
Train.D <- xgb.DMatrix(data=Train.x,label=Train.y,missing = NaN)
Test.x<- data.matrix(Test.x,rownames.force = NA)
View(Train.x)
#### Load trainging and testing data:
#### Source function:
source("../lib/function.R")
#### Specify Path:
train.path="../data/PerGame_2015/"
test.path="../data/PerGame_playoff_2016/"
tra=list.files(path = train.path, pattern = "*.csv")
tes=list.files(path = test.path, pattern = "*.csv")
tra1<-substr(tra, start=1, stop=nchar(tra)-9)
tes1<-substr(tes, start=1, stop=nchar(tes)-9)
train_data<-as.list(1:length(tra))
test_data<-as.list(1:length(tes))
names(train_data)<-tra
names(test_data)<-tes
## Read as list:
for (i in tra){
train_data[[i]]<-read.csv(paste(train.path,i,sep = ""),header = T,as.is=T)
}
# for (i in tes){
#  test_data[[i]]<-read.csv(paste(test.path,i,sep = ""),header = T,as.is=T)
#}
## Data Cleaning
wt<-0.9^seq(82, 1, by = -1)
wt<-wt/sum(wt)
ave_perf<-lapply(train_data,get_average,weight=wt)
x
get_average
test_data<-read.csv("../data/Test.csv")
test_data
test_data_features<-test_data
n_test<-nrow(test_data)
d_test<-ncol(test_data)
for(i in 1:n_test){
teamA<-test_data$TeamA[i]
opp<-test_data$Opp[i]
ind1<-which(tes1==teamA)
ind2<-which(tes1==opp)
test_data_features[i,3:34]<-c(ave_perf[ind1,],ave_perf[ind2,])
ave_perf[ind1,]<-(ave_perf[ind1,]+as.numeric(test_data[i,3:18]))/2
ave_perf[ind2,]<-(ave_perf[ind2,]+as.numeric(test_data[i,19:34]))/2
}
train_data<-Reduce(rbind,train_data)
test_data_features<-test_data_features[,-c(1,2)]
